{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPc8OxkuSm_5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itPXfFydaO4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "96AeKdNATQEO",
        "outputId": "83f9e04a-260e-44f3-b0ba-ef44cef67459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting flask-limiter\n",
            "  Downloading flask_limiter-3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Collecting limits>=3.13 (from flask-limiter)\n",
            "  Downloading limits-5.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting ordered-set<5,>4 (from flask-limiter)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: rich<14,>=12 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Collecting deprecated>=1.2 (from limits>=3.13->flask-limiter)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (2.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->limits>=3.13->flask-limiter) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12->flask-limiter) (0.1.2)\n",
            "Downloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading flask_limiter-3.12-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading limits-5.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=06b51968ebab646bbc8a41c05419a7627747d733194ac71d575c3f28083d6733\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: ordered-set, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, deprecated, wikipedia, nvidia-cusparse-cu12, nvidia-cudnn-cu12, limits, nvidia-cusolver-cu12, flask-limiter, flask-cors\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "    !pip install transformers sentence-transformers flask flask-cors flask-limiter wikipedia numpy torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NDD1y7uTTo1",
        "outputId": "d232e7b6-b32d-43de-f9bf-f3868f014d99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:src/pipeline.py not found at /content/src/pipeline.py. Please check your file upload.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Error: src/pipeline.py not found. Ensure 'src' folder is uploaded correctly.. Make sure your 'src' folder is uploaded correctly to the Colab environment.\n"
          ]
        }
      ],
      "source": [
        "    import sys\n",
        "    import os\n",
        "    import logging\n",
        "    import time\n",
        "\n",
        "    # Add the parent directory of 'src' to the Python path\n",
        "    # This assumes your 'src' folder is at the top level of your Colab session storage\n",
        "    # Adjust this path if you uploaded src into a subdirectory\n",
        "    project_root = os.getcwd() # Current directory where the notebook is running\n",
        "    sys.path.insert(0, project_root)\n",
        "\n",
        "    # Configure logging (optional, but helpful for debugging)\n",
        "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    try:\n",
        "        # Ensure the src directory is correctly in the path\n",
        "        if not os.path.exists(os.path.join(project_root, 'src', 'pipeline.py')):\n",
        "             logger.error(f\"src/pipeline.py not found at {os.path.join(project_root, 'src', 'pipeline.py')}. Please check your file upload.\")\n",
        "             raise FileNotFoundError(\"src/pipeline.py not found. Ensure 'src' folder is uploaded correctly.\")\n",
        "\n",
        "        from src.pipeline import DynamicRAGPipeline\n",
        "\n",
        "        logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "        # Initialize the pipeline\n",
        "        pipeline = DynamicRAGPipeline()\n",
        "        logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "        # Define a test query\n",
        "        test_query = \"What are the key features of Python?\"\n",
        "        logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "        # Process the query\n",
        "        # Note: The first query might be slow as models are loaded and data is fetched\n",
        "        response_data = pipeline.process_query(test_query)\n",
        "\n",
        "        # Print the results\n",
        "        print(\"\\n--- Response ---\")\n",
        "        print(f\"Query: {test_query}\")\n",
        "        print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "        print(\"\\n--- Sources ---\")\n",
        "        sources = response_data.get('sources', [])\n",
        "        if sources:\n",
        "            for i, source in enumerate(sources):\n",
        "                print(f\"Source {i+1}:\")\n",
        "                print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "                print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "                print(f\"  Relevance Score: {source.get('relevance_score', 'N/A')}\")\n",
        "        else:\n",
        "            print(\"No sources found.\")\n",
        "\n",
        "        print(\"\\n--- Metrics ---\")\n",
        "        metrics = response_data.get('metrics', {})\n",
        "        for key, value in metrics.items():\n",
        "            print(f\"  {key}: {value}\")\n",
        "\n",
        "        if 'error' in response_data:\n",
        "            print(f\"\\n--- Error ---\")\n",
        "            print(response_data['error'])\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"\\nError: {e}. Make sure your 'src' folder is uploaded correctly to the Colab environment.\")\n",
        "    except ImportError as e:\n",
        "        logger.error(f\"Failed to import modules. Make sure your 'src' directory is accessible and dependencies are installed. Error: {e}\")\n",
        "        print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and 'src' is in the path.\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"An error occurred during pipeline execution: {e}\")\n",
        "        print(f\"\\nAn unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pRuJ10fzT5-i",
        "outputId": "fc46933b-5f16-4902-9f94-62598d4071b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Import Error: No module named 'faiss'. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# No need to adjust sys.path if files are in the current directory\n",
        "# If you ever put them in a subdirectory, we'll need to add that directory to sys.path\n",
        "\n",
        "# Configure logging (optional, but helpful for debugging)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    # Import directly from the file names since they are at the root\n",
        "    from pipeline import DynamicRAGPipeline\n",
        "    from retriever import DynamicRetriever # Also need to import Retriever directly\n",
        "\n",
        "    # You might need to re-initialize the pipeline differently if it expects the retriever class\n",
        "    # directly during initialization, but let's try the simplest approach first.\n",
        "    # If DynamicRAGPipeline expects a specific retriever *instance*, this might need adjustment.\n",
        "\n",
        "    logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "    # Initialize the pipeline - it should instantiate DynamicRetriever internally\n",
        "    pipeline = DynamicRAGPipeline()\n",
        "    logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "    # Define a test query\n",
        "    test_query = \"What are the key features of Python?\"\n",
        "    logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "    # Process the query\n",
        "    # Note: The first query might be slow as models are loaded and data is fetched\n",
        "    response_data = pipeline.process_query(test_query)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(f\"Query: {test_query}\")\n",
        "    print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    sources = response_data.get('sources', [])\n",
        "    if sources:\n",
        "        for i, source in enumerate(sources):\n",
        "            print(f\"Source {i+1}:\")\n",
        "            print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "            print(f\"  Relevance Score: {source.get('relevance_score', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"No sources found.\")\n",
        "\n",
        "    print(\"\\n--- Metrics ---\")\n",
        "    metrics = response_data.get('metrics', {})\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    if 'error' in response_data:\n",
        "        print(f\"\\n--- Error ---\")\n",
        "        print(response_data['error'])\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nError: {e}. Please check your file upload in Colab.\")\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\")\n",
        "    print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"An unexpected error occurred during pipeline execution: {e}\")\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "# Example of getting conversation history (after processing queries)\n",
        "# history = pipeline.get_conversation_history()\n",
        "# print(\"\\n--- Conversation History ---\")\n",
        "# for entry in history:\n",
        "#    print(f\"Q: {entry['query']}\")\n",
        "#    print(f\"A: {entry['response'][:100]}...\") # Print truncated response\n",
        "#    print(\"-\" * 20)\n",
        "\n",
        "# Example of getting overall performance metrics\n",
        "# overall_metrics = pipeline.get_metrics()\n",
        "# print(\"\\n--- Overall Metrics ---\")\n",
        "# for key, value in overall_metrics.items():\n",
        "#    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z9JplJPtUNUz",
        "outputId": "b590b9f2-85e8-4ef5-f150-041bfae39af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting flask-limiter\n",
            "  Using cached flask_limiter-3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: limits>=3.13 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (5.2.0)\n",
            "Requirement already satisfied: ordered-set<5,>4 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (4.1.0)\n",
            "Requirement already satisfied: rich<14,>=12 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from limits>=3.13->flask-limiter) (1.2.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (2.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->limits>=3.13->flask-limiter) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12->flask-limiter) (0.1.2)\n",
            "Using cached flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Using cached flask_limiter-3.12-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: flask-limiter, flask-cors\n",
            "Successfully installed flask-cors-6.0.1 flask-limiter-3.12\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers flask flask-cors flask-limiter wikipedia numpy torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ltCHShF_UZsI",
        "outputId": "36401a79-c4b2-4b36-8444-560f5f3066ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:__main__:Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Import Error: No module named 'faiss'. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# No need to adjust sys.path if files are in the current directory\n",
        "# If you ever put them in a subdirectory, we'll need to add that directory to sys.path\n",
        "\n",
        "# Configure logging (optional, but helpful for debugging)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    # Import directly from the file names since they are at the root\n",
        "    from pipeline import DynamicRAGPipeline\n",
        "    from retriever import DynamicRetriever # Also need to import Retriever directly\n",
        "\n",
        "    # You might need to re-initialize the pipeline differently if it expects the retriever class\n",
        "    # directly during initialization, but let's try the simplest approach first.\n",
        "    # If DynamicRAGPipeline expects a specific retriever *instance*, this might need adjustment.\n",
        "\n",
        "    logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "    # Initialize the pipeline - it should instantiate DynamicRetriever internally\n",
        "    pipeline = DynamicRAGPipeline()\n",
        "    logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "    # Define a test query\n",
        "    test_query = \"What are the key features of Python?\"\n",
        "    logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "    # Process the query\n",
        "    # Note: The first query might be slow as models are loaded and data is fetched\n",
        "    response_data = pipeline.process_query(test_query)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(f\"Query: {test_query}\")\n",
        "    print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    sources = response_data.get('sources', [])\n",
        "    if sources:\n",
        "        for i, source in enumerate(sources):\n",
        "            print(f\"Source {i+1}:\")\n",
        "            print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "            print(f\"  Relevance Score: {source.get('relevance_score', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"No sources found.\")\n",
        "\n",
        "    print(\"\\n--- Metrics ---\")\n",
        "    metrics = response_data.get('metrics', {})\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    if 'error' in response_data:\n",
        "        print(f\"\\n--- Error ---\")\n",
        "        print(response_data['error'])\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nError: {e}. Please check your file upload in Colab.\")\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\")\n",
        "    print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"An unexpected error occurred during pipeline execution: {e}\")\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "# Example of getting conversation history (after processing queries)\n",
        "# history = pipeline.get_conversation_history()\n",
        "# print(\"\\n--- Conversation History ---\")\n",
        "# for entry in history:\n",
        "#    print(f\"Q: {entry['query']}\")\n",
        "#    print(f\"A: {entry['response'][:100]}...\") # Print truncated response\n",
        "#    print(\"-\" * 20)\n",
        "\n",
        "# Example of getting overall performance metrics\n",
        "# overall_metrics = pipeline.get_metrics()\n",
        "# print(\"\\n--- Overall Metrics ---\")\n",
        "# for key, value in overall_metrics.items():\n",
        "#    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YUv7fXLeUeR4",
        "outputId": "9c0e6d31-2933-41ae-c3c6-2d126e3d4224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: flask-limiter in /usr/local/lib/python3.11/dist-packages (3.12)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: limits>=3.13 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (5.2.0)\n",
            "Requirement already satisfied: ordered-set<5,>4 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (4.1.0)\n",
            "Requirement already satisfied: rich<14,>=12 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from limits>=3.13->flask-limiter) (1.2.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (2.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->limits>=3.13->flask-limiter) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12->flask-limiter) (0.1.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers flask flask-cors flask-limiter wikipedia numpy torch faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "d4b06a89865f4f07ae26f37499bfcd86",
            "45405ee18bb946b0a849aa32cb977158",
            "73cc58fee387473f8d36dc1da3e87dec",
            "705258bfcc274bcaa418d3574885b3cc",
            "c7297c8eddc246118dce4d53b4b54541",
            "4eb992f6ae6244dc848dcfa10d56fa51",
            "67da4c039ab249cbb926f669e40e4bbc",
            "560a1400009b4d6d881a619412d00af5",
            "9351d35a0c6e404ab1b14bd495cdd56d",
            "e1e5cb3646984880be57b4f486fb3cab",
            "9a64c7f61a0542ef8a0bb0d1e7081eee",
            "c1ef18bf03bc494298fd7f503367c0d4",
            "c963ba4cc24f4b64886734516a2ec9b6",
            "5a67c6b8eeaf47e68a21446f7c4ea129",
            "bf53df33bd3948268b4f8720f0ce0101",
            "acba020fd0e34c7190b556fca6b582a5",
            "f71ba0f0f3ad4fa082aa2cc65cf3b9a5"
          ]
        },
        "id": "5huqRoK9VM6e",
        "outputId": "de29b612-fe43-4c41-e420-09beb744c1e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4b06a89865f4f07ae26f37499bfcd86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45405ee18bb946b0a849aa32cb977158",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73cc58fee387473f8d36dc1da3e87dec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/2.67k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "705258bfcc274bcaa418d3574885b3cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7297c8eddc246118dce4d53b4b54541",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/669 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4eb992f6ae6244dc848dcfa10d56fa51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67da4c039ab249cbb926f669e40e4bbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "560a1400009b4d6d881a619412d00af5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9351d35a0c6e404ab1b14bd495cdd56d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1e5cb3646984880be57b4f486fb3cab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9a64c7f61a0542ef8a0bb0d1e7081eee",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1ef18bf03bc494298fd7f503367c0d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c963ba4cc24f4b64886734516a2ec9b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a67c6b8eeaf47e68a21446f7c4ea129",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf53df33bd3948268b4f8720f0ce0101",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acba020fd0e34c7190b556fca6b582a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f71ba0f0f3ad4fa082aa2cc65cf3b9a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Response ---\n",
            "Query: What are the key features of Python?\n",
            "Response: Can you clarify what exactly you're asking about in: It is also possible?\n",
            "\n",
            "--- Sources ---\n",
            "No sources found.\n",
            "\n",
            "--- Metrics ---\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# No need to adjust sys.path if files are in the current directory\n",
        "# If you ever put them in a subdirectory, we'll need to add that directory to sys.path\n",
        "\n",
        "# Configure logging (optional, but helpful for debugging)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    # Import directly from the file names since they are at the root\n",
        "    from pipeline import DynamicRAGPipeline\n",
        "    from retriever import DynamicRetriever # Also need to import Retriever directly\n",
        "\n",
        "    # You might need to re-initialize the pipeline differently if it expects the retriever class\n",
        "    # directly during initialization, but let's try the simplest approach first.\n",
        "    # If DynamicRAGPipeline expects a specific retriever *instance*, this might need adjustment.\n",
        "\n",
        "    logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "    # Initialize the pipeline - it should instantiate DynamicRetriever internally\n",
        "    pipeline = DynamicRAGPipeline()\n",
        "    logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "    # Define a test query\n",
        "    test_query = \"What are the key features of Python?\"\n",
        "    logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "    # Process the query\n",
        "    # Note: The first query might be slow as models are loaded and data is fetched\n",
        "    response_data = pipeline.process_query(test_query)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(f\"Query: {test_query}\")\n",
        "    print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    sources = response_data.get('sources', [])\n",
        "    if sources:\n",
        "        for i, source in enumerate(sources):\n",
        "            print(f\"Source {i+1}:\")\n",
        "            print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "            print(f\"  Relevance Score: {source.get('relevance_score', 'N/A')}\")\n",
        "    else:\n",
        "        print(\"No sources found.\")\n",
        "\n",
        "    print(\"\\n--- Metrics ---\")\n",
        "    metrics = response_data.get('metrics', {})\n",
        "    for key, value in metrics.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    if 'error' in response_data:\n",
        "        print(f\"\\n--- Error ---\")\n",
        "        print(response_data['error'])\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"\\nError: {e}. Please check your file upload in Colab.\")\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\")\n",
        "    print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"An unexpected error occurred during pipeline execution: {e}\")\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n",
        "\n",
        "# Example of getting conversation history (after processing queries)\n",
        "# history = pipeline.get_conversation_history()\n",
        "# print(\"\\n--- Conversation History ---\")\n",
        "# for entry in history:\n",
        "#    print(f\"Q: {entry['query']}\")\n",
        "#    print(f\"A: {entry['response'][:100]}...\") # Print truncated response\n",
        "#    print(\"-\" * 20)\n",
        "\n",
        "# Example of getting overall performance metrics\n",
        "# overall_metrics = pipeline.get_metrics()\n",
        "# print(\"\\n--- Overall Metrics ---\")\n",
        "# for key, value in overall_metrics.items():\n",
        "#    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UZ77sAJ5Z72R",
        "outputId": "bc1e028e-c050-44df-f4c4-8b055c2b6b12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: flask-limiter in /usr/local/lib/python3.11/dist-packages (3.12)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: limits>=3.13 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (5.2.0)\n",
            "Requirement already satisfied: ordered-set<5,>4 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (4.1.0)\n",
            "Requirement already satisfied: rich<14,>=12 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (13.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from limits>=3.13->flask-limiter) (1.2.18)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (2.19.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->limits>=3.13->flask-limiter) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12->flask-limiter) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentence-transformers flask flask-cors flask-limiter wikipedia numpy torch faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hGZlhGLbZAU-",
        "outputId": "1f69141e-6ab6-42bc-cd8d-6f6efe7a11fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Response ---\n",
            "Query: What are the key features of Python?\n",
            "Response: Can you clarify what exactly you're asking about in: It is also possible?\n",
            "\n",
            "--- Sources ---\n",
            "No sources found.\n",
            "\n",
            "--- Metrics ---\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "\n",
        "# Configure logging (optional, but helpful for debugging)\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "try:\n",
        "    # Import directly from the file names since they are at the root in Colab\n",
        "    from pipeline import DynamicRAGPipeline\n",
        "    from retriever import DynamicRetriever # Ensure retriever is also importable if needed elsewhere\n",
        "\n",
        "    logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "    # Initialize the pipeline - it should instantiate DynamicRetriever internally\n",
        "    pipeline = DynamicRAGPipeline()\n",
        "    logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "    # Define a test query\n",
        "    test_query = \"What are the key features of Python?\"\n",
        "    logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "    # Process the query\n",
        "    # Note: The first query might be slow as models are loaded and data is fetched\n",
        "    response_data = pipeline.process_query(test_query)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(f\"Query: {test_query}\")\n",
        "    print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    sources = response_data.get('sources', [])\n",
        "    if sources:\n",
        "        for i, source in enumerate(sources):\n",
        "            print(f\"Source {i+1}:\")\n",
        "            print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "            # Check for relevance_score before trying to format\n",
        "            relevance_score = source.get('relevance_score')\n",
        "            if relevance_score is not None:\n",
        "                 print(f\"  Relevance Score: {relevance_score:.4f}\") # Format score for clarity\n",
        "            else:\n",
        "                 print(f\"  Relevance Score: N/A\")\n",
        "    else:\n",
        "        print(\"No sources found.\")\n",
        "\n",
        "    print(\"\\n--- Metrics ---\")\n",
        "    metrics = response_data.get('metrics', {})\n",
        "    for key, value in metrics.items():\n",
        "        # Basic formatting for metrics\n",
        "        if isinstance(value, float):\n",
        "             print(f\"  {key}: {value:.4f}\")\n",
        "        else:\n",
        "             print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "    if 'error' in response_data:\n",
        "        print(f\"\\n--- Error ---\")\n",
        "        print(response_data['error'])\n",
        "\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\")\n",
        "    print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"An unexpected error occurred during pipeline execution: {e}\")\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fXAVcaMdap3N",
        "outputId": "284ff33d-bd9e-4a5a-cea9-81117c856ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Response ---\n",
            "Query: What are the key features of Python?\n",
            "Response: Can you clarify what exactly you're asking about in: It is also possible?\n",
            "\n",
            "--- Sources ---\n",
            "No sources found.\n",
            "\n",
            "--- Metrics ---\n"
          ]
        }
      ],
      "source": [
        "# ... (the rest of your Python script) ...\n",
        "\n",
        "try:\n",
        "    # Import directly from the file names since they are at the root in Colab\n",
        "    from pipeline import DynamicRAGPipeline\n",
        "    from retriever import DynamicRetriever # Ensure retriever is also importable if needed elsewhere\n",
        "\n",
        "    logger.info(\"Initializing the DynamicRAGPipeline...\")\n",
        "    # Initialize the pipeline - it should instantiate DynamicRetriever internally\n",
        "    pipeline = DynamicRAGPipeline()\n",
        "    logger.info(\"DynamicRAGPipeline initialized.\")\n",
        "\n",
        "    # Define a test query\n",
        "    test_query = \"What are the key features of Python?\"\n",
        "    logger.info(f\"Processing test query: '{test_query}'\")\n",
        "\n",
        "    # Process the query\n",
        "    # Note: The first query might be slow as models are loaded and data is fetched\n",
        "    response_data = pipeline.process_query(test_query)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Response ---\")\n",
        "    print(f\"Query: {test_query}\")\n",
        "    print(f\"Response: {response_data.get('response', 'N/A')}\")\n",
        "\n",
        "    print(\"\\n--- Sources ---\")\n",
        "    sources = response_data.get('sources', [])\n",
        "    if sources:\n",
        "        for i, source in enumerate(sources):\n",
        "            print(f\"Source {i+1}:\")\n",
        "            print(f\"  Title: {source.get('title', 'N/A')}\")\n",
        "            print(f\"  URL: {source.get('url', 'N/A')}\")\n",
        "            # Check for relevance_score before trying to format\n",
        "            relevance_score = source.get('relevance_score')\n",
        "            if relevance_score is not None:\n",
        "                 print(f\"  Relevance Score: {relevance_score:.4f}\") # Format score for clarity\n",
        "            else:\n",
        "                 print(f\"  Relevance Score: N/A\")\n",
        "    else:\n",
        "        print(\"No sources found.\")\n",
        "\n",
        "    print(\"\\n--- Metrics ---\")\n",
        "    metrics = response_data.get('metrics', {})\n",
        "    for key, value in metrics.items():\n",
        "        # Basic formatting for metrics\n",
        "        if isinstance(value, float):\n",
        "             print(f\"  {key}: {value:.4f}\")\n",
        "        else:\n",
        "             print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "    if 'error' in response_data:\n",
        "        print(f\"\\n--- Error ---\")\n",
        "        print(response_data['error'])\n",
        "\n",
        "except ImportError as e:\n",
        "    logger.error(f\"Failed to import modules. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded.\")\n",
        "    print(f\"\\nImport Error: {e}. Ensure all necessary packages are installed (run the pip install cell) and the .py files are directly uploaded to the root level.\")\n",
        "except Exception as e:\n",
        "    logger.error(f\"An unexpected error occurred during pipeline execution: {e}\")\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uQkbhkFpa2b9",
        "outputId": "2bba535d-5eb2-4f2b-f557-0849447cfc7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: wikipedia 1.4.0\n",
            "Uninstalling wikipedia-1.4.0:\n",
            "  Successfully uninstalled wikipedia-1.4.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: flask-limiter in /usr/local/lib/python3.11/dist-packages (3.12)\n",
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: limits>=3.13 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (5.2.0)\n",
            "Requirement already satisfied: ordered-set<5,>4 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (4.1.0)\n",
            "Requirement already satisfied: rich<14,>=12 in /usr/local/lib/python3.11/dist-packages (from flask-limiter) (13.9.4)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2 in /usr/local/lib/python3.11/dist-packages (from limits>=3.13->flask-limiter) (1.2.18)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=12->flask-limiter) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2->limits>=3.13->flask-limiter) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=12->flask-limiter) (0.1.2)\n",
            "Building wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15383 sha256=428cae3b28a6ae777512775c438ec3c8a84e182b1d35b3026543fce92bccbb04\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: wikipedia-api\n",
            "Successfully installed wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y wikipedia\n",
        "!pip install transformers sentence-transformers flask flask-cors flask-limiter wikipedia-api numpy torch faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cQavpQfQa6TH"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import logging\n",
        "import time\n",
        "from collections import defaultdict\n",
        "# import wikipedia # Remove this line\n",
        "import wikipediaapi # Add this line\n",
        "import concurrent.futures\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from functools import lru_cache\n",
        "import requests\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "import json\n",
        "import os\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class DynamicRetriever:\n",
        "    \"\"\"\n",
        "    Dynamic retrieval system that fetches Wikipedia data on-demand and retrieves targeted information.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str = \"facebook-dpr-ctx_encoder-single-nq-base\"):\n",
        "        \"\"\"\n",
        "        Initialize the dynamic retriever with a sentence transformer model.\n",
        "\n",
        "        Args:\n",
        "            model_name: Name of the sentence transformer model to use\n",
        "        \"\"\"\n",
        "        logger.info(f\"Initializing DynamicRetriever with model: {model_name}\")\n",
        "\n",
        "        # Initialize models and storage\n",
        "        self.embedding_model = SentenceTransformer(model_name)\n",
        "        self.embedding_dim = self.embedding_model.get_sentence_embedding_dimension()\n",
        "        self.documents = []\n",
        "        self.document_topics = []\n",
        "        self.topic_hierarchy = {}\n",
        "\n",
        "        # Initialize metrics\n",
        "        self.metrics = {\n",
        "            'retrieval_time': [],\n",
        "            'narrowing_time': [],\n",
        "            'topic_accuracy': [],\n",
        "            'wikipedia_fetch_time': []\n",
        "        }\n",
        "\n",
        "        # Initialize Wikipedia API (using wikipedia-api)\n",
        "        # User-Agent is recommended for ethical use of Wikipedia API\n",
        "        self.wiki_wiki = wikipediaapi.Wikipedia(\n",
        "            'DynamicRAGPipeline (contact@example.com)', # Replace with your contact info or app name\n",
        "            'en'  # Language\n",
        "        )\n",
        "\n",
        "        # Initialize cache directory\n",
        "        self.cache_dir = os.path.join(os.path.dirname(__file__), '..', 'cache')\n",
        "        os.makedirs(self.cache_dir, exist_ok=True)\n",
        "\n",
        "        logger.info(\"DynamicRetriever initialized successfully\")\n",
        "\n",
        "    # Keep _get_cached_page and _cache_page for now, but they might need adjustments later\n",
        "    # if the data structure from wikipedia-api is different.\n",
        "    @lru_cache(maxsize=1000)\n",
        "    def _get_cached_page(self, title: str) -> Optional[Dict]:\n",
        "        \"\"\"Get a Wikipedia page from cache if available.\"\"\"\n",
        "        cache_file = os.path.join(self.cache_dir, f\"{title.lower().replace(' ', '_')}.json\")\n",
        "        if os.path.exists(cache_file):\n",
        "            try:\n",
        "                with open(cache_file, 'r', encoding='utf-8') as f:\n",
        "                    # Assuming cached data structure is compatible for now\n",
        "                    return json.load(f)\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error reading cache for {title}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    def _cache_page(self, title: str, content: Dict):\n",
        "        \"\"\"Cache a Wikipedia page.\"\"\"\n",
        "        cache_file = os.path.join(self.cache_dir, f\"{title.lower().replace(' ', '_')}.json\")\n",
        "        try:\n",
        "            with open(cache_file, 'w', encoding='utf-8') as f:\n",
        "                # Assuming cached data structure is compatible for now\n",
        "                json.dump(content, f, ensure_ascii=False, indent=2)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error caching {title}: {str(e)}\")\n",
        "\n",
        "\n",
        "    def _handle_disambiguation(self, title: str, options: List[str]) -> Optional[str]:\n",
        "        \"\"\"Handle Wikipedia disambiguation pages by selecting the most relevant option.\"\"\"\n",
        "        if not options:\n",
        "            return None\n",
        "\n",
        "        # Get embeddings for all options\n",
        "        option_embeddings = self.embedding_model.encode(options)\n",
        "        title_embedding = self.embedding_model.encode([title])[0]\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = np.dot(option_embeddings, title_embedding)\n",
        "        best_idx = np.argmax(similarities)\n",
        "\n",
        "        if similarities[best_idx] > 0.5:  # Only return if confidence is high enough\n",
        "            return options[best_idx]\n",
        "        return None\n",
        "\n",
        "    def fetch_wikipedia_data(self, query: str, max_pages: int = 3) -> List[Dict]:\n",
        "        \"\"\"Fetch relevant Wikipedia pages for a query using wikipedia-api.\"\"\"\n",
        "        start_time = time.time()\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # Temporarily disable cache check while testing wikipedia-api\n",
        "            # cached_result = self._get_cached_page(query)\n",
        "            # if cached_result:\n",
        "            #     logger.info(f\"Retrieved {query} from cache\")\n",
        "            #     return cached_result\n",
        "\n",
        "            # Search Wikipedia using wikipedia-api\n",
        "            # Note: wikipedia-api's search returns a list of titles\n",
        "            search_results = self.wiki_wiki.page(query).search_results\n",
        "\n",
        "            if not search_results:\n",
        "                logger.warning(f\"No Wikipedia pages found for query: {query}\")\n",
        "                return results\n",
        "\n",
        "            # Process each search result (title and pageid tuple)\n",
        "            for page_item in search_results[:max_pages]:\n",
        "                title = page_item[0] # The title is the first element of the tuple\n",
        "                try:\n",
        "                    # Get the full page using wikipedia-api\n",
        "                    page = self.wiki_wiki.page(title)\n",
        "\n",
        "                    if not page.exists():\n",
        "                         logger.warning(f\"Page does not exist for title: {title}\")\n",
        "                         continue\n",
        "\n",
        "                    # wikipedia-api handles redirects and basic disambiguation better\n",
        "                    # We might still need custom disambiguation if page.text indicates it\n",
        "                    # For now, let's assume page.text is the main content\n",
        "\n",
        "\n",
        "                    # Prepare page data\n",
        "                    page_data = {\n",
        "                        'title': page.title,\n",
        "                        'url': page.fullurl, # Use fullurl for the URL\n",
        "                        'summary': page.summary,\n",
        "                        'content': page.text, # Use page.text for full content\n",
        "                        'topics': self._extract_topics(page.text)\n",
        "                    }\n",
        "\n",
        "                    # Temporarily disable caching while testing wikipedia-api\n",
        "                    # self._cache_page(page.title, page_data)\n",
        "                    results.append(page_data)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Error fetching page {title} with wikipedia-api: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error fetching Wikipedia data with wikipedia-api: {str(e)}\")\n",
        "\n",
        "        finally:\n",
        "            fetch_time = time.time() - start_time\n",
        "            # Ensure metrics list contains only floats\n",
        "            self.metrics['wikipedia_fetch_time'].append(float(fetch_time)) # Ensure float\n",
        "            logger.info(f\"Wikipedia fetch completed in {fetch_time:.2f}s\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _extract_topics(self, content: str) -> List[str]:\n",
        "        \"\"\"Extract potential topics from content using simple heuristics.\"\"\"\n",
        "        # Split content into sentences and look for topic indicators\n",
        "        sentences = content.split('.')\n",
        "        topics = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Look for common topic indicators\n",
        "            if any(indicator in sentence.lower() for indicator in ['is a', 'refers to', 'deals with', 'about']):\n",
        "                # Extract the subject\n",
        "                words = sentence.split()\n",
        "                if len(words) > 3:\n",
        "                    topics.append(' '.join(words[:4]))\n",
        "\n",
        "        return list(set(topics))  # Remove duplicates\n",
        "\n",
        "\n",
        "    def add_topic_hierarchy(self, parent_topic: str, subtopics: List[str]) -> None:\n",
        "        \"\"\"\n",
        "        Add a topic hierarchy for narrowing down topics.\n",
        "\n",
        "        Args:\n",
        "            parent_topic: The broader parent topic\n",
        "            subtopics: List of more specific subtopics\n",
        "        \"\"\"\n",
        "        self.topic_hierarchy[parent_topic] = subtopics\n",
        "        logger.info(f\"Added topic hierarchy: {parent_topic} -> {subtopics}\")\n",
        "\n",
        "\n",
        "    def identify_broad_topic(self, query: str) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Identify the broad topic of a user query by fetching relevant Wikipedia pages.\n",
        "\n",
        "        Args:\n",
        "            query: The user query text\n",
        "\n",
        "        Returns:\n",
        "            List of potential topics with confidence scores\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Fetch Wikipedia data for the query using the updated method\n",
        "        wiki_data = self.fetch_wikipedia_data(query)\n",
        "\n",
        "        if not wiki_data:\n",
        "            return []\n",
        "\n",
        "        # Clear previous session data\n",
        "        self.documents = []\n",
        "        self.document_topics = []\n",
        "        self.index = faiss.IndexFlatL2(self.embedding_dim)\n",
        "\n",
        "        # Add fetched documents to the index\n",
        "        for doc in wiki_data:\n",
        "            # Use 'content' from the new page_data structure\n",
        "            document_content = doc.get('content', '')\n",
        "            if not document_content:\n",
        "                 logger.warning(f\"No content found for document: {doc.get('title', 'N/A')}\")\n",
        "                 continue # Skip if content is empty\n",
        "\n",
        "            self.documents.append(document_content)\n",
        "            self.document_topics.append(doc.get('topics', [])) # Use get with default for safety\n",
        "\n",
        "            # Create and add embedding\n",
        "            try:\n",
        "                embedding = self.embedding_model.encode(document_content)\n",
        "                embedding = embedding.reshape(1, -1)\n",
        "                self.index.add(embedding)\n",
        "            except Exception as e:\n",
        "                 logger.error(f\"Error creating embedding for document {doc.get('title', 'N/A')}: {e}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "        # Get query embedding\n",
        "        query_embedding = self.embedding_model.encode(query)\n",
        "        query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "        # Find similar documents\n",
        "        k = min(5, self.index.ntotal)\n",
        "        if k == 0:\n",
        "             logger.warning(\"FAISS index is empty after processing wiki data.\")\n",
        "             return []\n",
        "\n",
        "        try:\n",
        "            distances, indices = self.index.search(query_embedding, k)\n",
        "        except Exception as e:\n",
        "             logger.error(f\"Error searching FAISS index: {e}\")\n",
        "             return []\n",
        "\n",
        "\n",
        "        # Count topic occurrences in retrieved documents\n",
        "        topic_scores = defaultdict(float)\n",
        "        # Check if indices[0] is not empty before iterating\n",
        "        if indices is not None and len(indices) > 0 and len(indices[0]) > 0:\n",
        "             for i, doc_idx in enumerate(indices[0]):\n",
        "                 # Ensure doc_idx is within the bounds of self.document_topics\n",
        "                 if 0 <= doc_idx < len(self.document_topics):\n",
        "                      similarity_score = 1.0 / (1.0 + distances[0][i])  # Convert distance to similarity\n",
        "\n",
        "                      for topic in self.document_topics[doc_idx]:\n",
        "                          topic_scores[topic] += similarity_score\n",
        "                 else:\n",
        "                      logger.warning(f\"Invalid document index {doc_idx} encountered during topic scoring.\")\n",
        "        else:\n",
        "             logger.warning(\"No indices returned from FAISS search.\")\n",
        "\n",
        "\n",
        "        # Sort topics by score\n",
        "        sorted_topics = sorted(\n",
        "            [(topic, score) for topic, score in topic_scores.items()],\n",
        "            key=lambda x: x[1],\n",
        "            reverse=True\n",
        "        )\n",
        "\n",
        "        self.metrics['narrowing_time'].append(time.time() - start_time)\n",
        "        return sorted_topics\n",
        "\n",
        "\n",
        "    def generate_clarification_questions(self, broad_topic: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Generate clarification questions to narrow down a broad topic.\n",
        "\n",
        "        Args:\n",
        "            broad_topic: The broad topic identified from the user query\n",
        "\n",
        "        Returns:\n",
        "            List of clarification questions\n",
        "        \"\"\"\n",
        "        questions = []\n",
        "\n",
        "        # Check if we have subtopics for this topic\n",
        "        if broad_topic in self.topic_hierarchy:\n",
        "            subtopics = self.topic_hierarchy[broad_topic]\n",
        "\n",
        "            # Create general question\n",
        "            general_question = f\"Your query is about {broad_topic}. Could you specify which aspect you're interested in?\"\n",
        "            questions.append(general_question)\n",
        "\n",
        "            # Create specific questions for each subtopic\n",
        "            for subtopic in subtopics:\n",
        "                question = f\"Are you interested in {subtopic} specifically?\"\n",
        "                questions.append(question)\n",
        "\n",
        "            # Add open-ended question\n",
        "            questions.append(f\"Is there a specific aspect of {broad_topic} you want to focus on?\")\n",
        "        else:\n",
        "            # Generic questions if no subtopics are defined\n",
        "            questions = [\n",
        "                f\"Could you provide more details about what aspect of {broad_topic} you're interested in?\",\n",
        "                f\"What specific information about {broad_topic} are you looking for?\",\n",
        "                f\"Are you looking for general information about {broad_topic} or something specific?\"\n",
        "            ]\n",
        "\n",
        "        return questions\n",
        "\n",
        "    # Keep the retrieve method, but it calls the updated fetch_wikipedia_data\n",
        "    def retrieve(self, query: str, topics: Optional[List[str]] = None, k: int = 5) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Retrieve documents based on query by fetching from Wikipedia.\n",
        "\n",
        "        Args:\n",
        "            query: The user query\n",
        "            topics: Optional list of topics to filter results\n",
        "            k: Number of documents to retrieve\n",
        "\n",
        "        Returns:\n",
        "            List of relevant documents (as dictionaries with title, url, summary, content)\n",
        "        \"\"\"\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Fetch Wikipedia data for the query using the updated method\n",
        "        wiki_data = self.fetch_wikipedia_data(query, max_pages=k)\n",
        "\n",
        "        if not wiki_data:\n",
        "            return []\n",
        "\n",
        "        # Clear previous session data (only needed if not clearing in fetch_wikipedia_data)\n",
        "        # If we are clearing in identify_broad_topic and retrieve, maybe it's okay.\n",
        "        # Let's stick to clearing in identify_broad_topic for topic extraction\n",
        "        # and build the index locally in retrieve for document retrieval.\n",
        "\n",
        "        # Build a temporary index for retrieved documents for ranking\n",
        "        temp_documents = []\n",
        "        temp_document_topics = [] # Keep track of topics for filtering\n",
        "        temp_index = faiss.IndexFlatL2(self.embedding_dim)\n",
        "\n",
        "        for doc in wiki_data:\n",
        "            document_content = doc.get('content', '')\n",
        "            if not document_content:\n",
        "                 logger.warning(f\"No content found for document: {doc.get('title', 'N/A')}\")\n",
        "                 continue # Skip if content is empty\n",
        "\n",
        "            temp_documents.append(doc) # Store the whole document dict\n",
        "            temp_document_topics.append(doc.get('topics', [])) # Store topics\n",
        "\n",
        "            try:\n",
        "                embedding = self.embedding_model.encode(document_content)\n",
        "                embedding = embedding.reshape(1, -1)\n",
        "                temp_index.add(embedding)\n",
        "            except Exception as e:\n",
        "                 logger.error(f\"Error creating embedding for document {doc.get('title', 'N/A')}: {e}\")\n",
        "                 continue\n",
        "\n",
        "\n",
        "        # Get query embedding\n",
        "        query_embedding = self.embedding_model.encode(query)\n",
        "        query_embedding = query_embedding.reshape(1, -1)\n",
        "\n",
        "        # Retrieve from index\n",
        "        k_actual = min(k, temp_index.ntotal)\n",
        "        if k_actual == 0:\n",
        "            logger.warning(\"FAISS index is empty in retrieve method.\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            distances, indices = temp_index.search(query_embedding, k_actual)\n",
        "        except Exception as e:\n",
        "             logger.error(f\"Error searching FAISS index in retrieve: {e}\")\n",
        "             return []\n",
        "\n",
        "\n",
        "        # Filter by topics if specified and collect results\n",
        "        results_with_distance = []\n",
        "        if indices is not None and len(indices) > 0 and len(indices[0]) > 0:\n",
        "            for i, doc_idx in enumerate(indices[0]):\n",
        "                 # Ensure doc_idx is within the bounds\n",
        "                 if 0 <= doc_idx < len(temp_documents):\n",
        "                      # If topics filter is provided, check if document has any of those topics\n",
        "                      if topics is None or any(topic in temp_document_topics[doc_idx] for topic in topics):\n",
        "                           results_with_distance.append((temp_documents[doc_idx], distances[0][i]))\n",
        "                 else:\n",
        "                      logger.warning(f\"Invalid document index {doc_idx} encountered during retrieval.\")\n",
        "        else:\n",
        "             logger.warning(\"No indices returned from FAISS search in retrieve.\")\n",
        "\n",
        "\n",
        "        # Sort by relevance (distance) and return top k documents (the original dicts)\n",
        "        results_with_distance.sort(key=lambda x: x[1])\n",
        "        retrieved_documents = [doc for doc, distance in results_with_distance[:k]]\n",
        "\n",
        "\n",
        "        self.metrics['retrieval_time'].append(time.time() - start_time)\n",
        "        return retrieved_documents\n",
        "\n",
        "    def get_performance_metrics(self) -> Dict:\n",
        "        \"\"\"Get the average performance metrics\"\"\"\n",
        "        metrics = {}\n",
        "\n",
        "        # Calculate averages and counts for each metric\n",
        "        for key, values in self.metrics.items():\n",
        "            if values:\n",
        "                # Ensure values are treated as floats for summation and averaging\n",
        "                float_values = [float(v) for v in values if isinstance(v, (int, float))]\n",
        "                if float_values:\n",
        "                    metrics[f'avg_{key}'] = sum(float_values) / len(float_values)\n",
        "                    metrics[f'max_{key}'] = max(float_values)\n",
        "                    # metrics[f'min_{key}'] = min(float_values) # Min was removed in previous edit\n",
        "                    metrics[f'count_{key}'] = len(float_values)\n",
        "                else:\n",
        "                     metrics[f'avg_{key}'] = 0.0\n",
        "                     metrics[f'max_{key}'] = 0.0\n",
        "                     # metrics[f'min_{key}'] = 0.0 # Min was removed\n",
        "                     metrics[f'count_{key}'] = 0\n",
        "            else:\n",
        "                metrics[f'avg_{key}'] = 0.0\n",
        "                metrics[f'max_{key}'] = 0.0\n",
        "                # metrics[f'min_{key}'] = 0.0 # Min was removed\n",
        "                metrics[f'count_{key}'] = 0\n",
        "\n",
        "        # Add overall query counts and rates\n",
        "        # Assuming these are handled in the pipeline now, but keeping here for completeness if needed\n",
        "        # total_queries = self.metrics.get('total_queries', 0)\n",
        "        # successful_queries = self.metrics.get('successful_queries', 0)\n",
        "        # failed_queries = self.metrics.get('failed_queries', 0)\n",
        "        #\n",
        "        # metrics['total_queries'] = total_queries\n",
        "        # metrics['successful_queries'] = successful_queries\n",
        "        # metrics['failed_queries'] = failed_queries\n",
        "        # metrics['success_rate'] = (successful_queries / total_queries * 100 if total_queries > 0 else 0)\n",
        "\n",
        "\n",
        "        return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1b895c04",
        "outputId": "957f1ea3-a8a7-4291-a76c-f590f1871d9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for 'pipeline.py' in '/content'...\n",
            "Found 'pipeline.py' at: /content/pipeline.py\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def find_file(filename, search_path):\n",
        "    \"\"\"Recursively finds a file in a directory.\"\"\"\n",
        "    for root, dirs, files in os.walk(search_path):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "        # Optionally, you can add checks here to exclude certain directories if needed\n",
        "        # e.g., if 'venv' in dirs: dirs.remove('venv')\n",
        "\n",
        "    return None\n",
        "\n",
        "# Define the filename to search for\n",
        "filename_to_find = 'pipeline.py'\n",
        "\n",
        "# Define the directory to start the search from (e.g., the root of your Colab session)\n",
        "# You might need to adjust this path based on where you think you uploaded the file.\n",
        "# Common locations are '.' (current directory) or '/content'.\n",
        "search_directory = '/content' # Or '.'\n",
        "\n",
        "print(f\"Searching for '{filename_to_find}' in '{search_directory}'...\")\n",
        "\n",
        "found_path = find_file(filename_to_find, search_directory)\n",
        "\n",
        "if found_path:\n",
        "    print(f\"Found '{filename_to_find}' at: {found_path}\")\n",
        "else:\n",
        "    print(f\"'{filename_to_find}' not found in '{search_directory}' or its subdirectories.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "s-bv52PfjMQw"
      },
      "outputs": [],
      "source": [
        "test_queries = [\n",
        "    \"What are transformers in machine learning?\",\n",
        "    \"Tell me about applications of AI in healthcare.\",\n",
        "    \"Explain the basics of quantum computing.\",\n",
        "    \"What is the difference between supervised and unsupervised learning?\",\n",
        "    \"What is BERT used for?\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XeOdfac-jsY1"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "from retriever import DynamicRetriever\n",
        "\n",
        "# Baseline just means: get context and pass to BART without clarifications\n",
        "baseline_pipeline = DynamicRAGPipeline()\n",
        "baseline_pipeline.retriever = DynamicRetriever()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "K9zMW9MGoOvr"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "from retriever import DynamicRetriever\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2xl539wqrywb",
        "outputId": "30be202b-e18e-4b89-e200-d9bcb626d292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "by45iBQWr38L",
        "outputId": "d64ac4a9-3610-4e63-93e3-2eb1377d337b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Collecting wikipedia\n",
            "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "79f92991fd504e3384d51692a29c5251",
              "pip_warning": {
                "packages": [
                  "wikipedia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install sentence-transformers transformers wikipedia flask flask-cors torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P2VlwpAwska9"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "from retriever import DynamicRetriever\n",
        "\n",
        "baseline_pipeline = DynamicRAGPipeline()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B6x0v6Gnv48r",
        "outputId": "d56ac00a-2d92-4b9d-fea8-aaee0effc9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu sentence-transformers transformers wikipedia flask flask-cors torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KcuUnjC9wqX_",
        "outputId": "56c73d51-ff8c-48dd-dd94-c43e6cf31335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu sentence-transformers transformers wikipedia flask flask-cors torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "djmQh3Ogw67l"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "\n",
        "# Initialize your DA-RAG pipeline\n",
        "pipeline = DynamicRAGPipeline()\n",
        "\n",
        "# Define some test queries\n",
        "test_queries = [\n",
        "    \"What are the applications of AI in healthcare?\",\n",
        "    \"Tell me about transformers in NLP.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain backpropagation.\",\n",
        "    \"What are the uses of quantum computing?\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ub5dNcncxSE3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef39aa4d-3ac0-48a4-e8fd-2d7b5cab071e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Query: What are the applications of AI in healthcare?\n",
            "\n",
            "🔍 Query: Tell me about transformers in NLP.\n",
            "\n",
            "🔍 Query: What is machine learning?\n",
            "\n",
            "🔍 Query: Explain backpropagation.\n",
            "\n",
            "🔍 Query: What are the uses of quantum computing?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n🔍 Query: {query}\")\n",
        "\n",
        "    # ---- DA-RAG ----\n",
        "    da_result = pipeline.process_query(query)\n",
        "    da_response = da_result.get(\"response\", \"N/A\")\n",
        "\n",
        "    # ---- Baseline ----\n",
        "    # Fetch documents manually and pass them directly to the same BART generator\n",
        "    try:\n",
        "        docs = pipeline.retriever.fetch_wikipedia_data(query)\n",
        "        baseline_context = \"\\n\".join([doc['summary'] for doc in docs]) if docs else \"No docs found.\"\n",
        "        baseline_response = pipeline._generate_response(query, baseline_context)\n",
        "    except Exception as e:\n",
        "        baseline_response = f\"Error: {str(e)}\"\n",
        "\n",
        "    # Save results\n",
        "    results.append({\n",
        "        \"Query\": query,\n",
        "        \"DA-RAG Response\": da_response,\n",
        "        \"Baseline Response\": baseline_response,\n",
        "        \"DA-RAG Length\": len(da_response.split()),\n",
        "        \"Baseline Length\": len(baseline_response.split())\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wHPKBRBs0eg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb07a265-605b-4939-e553-ef3e3ab9cb49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Query: What are the applications of AI in healthcare?\n",
            "\n",
            "🔍 Query: Tell me about transformers in NLP.\n",
            "\n",
            "🔍 Query: What is machine learning?\n",
            "\n",
            "🔍 Query: Explain backpropagation.\n",
            "\n",
            "🔍 Query: What are the uses of quantum computing?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n🔍 Query: {query}\")\n",
        "\n",
        "    # ---- DA-RAG ----\n",
        "    da_result = pipeline.process_query(query)\n",
        "    da_response = da_result.get(\"response\", \"N/A\")\n",
        "\n",
        "    # ---- Baseline ----\n",
        "    # Fetch documents manually and pass them directly to the same BART generator\n",
        "    try:\n",
        "        docs = pipeline.retriever.fetch_wikipedia_data(query)\n",
        "        baseline_context = \"\\n\".join([doc['summary'] for doc in docs]) if docs else \"No docs found.\"\n",
        "        baseline_response = pipeline._generate_response(query, baseline_context)\n",
        "    except Exception as e:\n",
        "        baseline_response = f\"Error: {str(e)}\"\n",
        "\n",
        "    # Save results\n",
        "    results.append({\n",
        "        \"Query\": query,\n",
        "        \"DA-RAG Response\": da_response,\n",
        "        \"Baseline Response\": baseline_response,\n",
        "        \"DA-RAG Length\": len(da_response.split()),\n",
        "        \"Baseline Length\": len(baseline_response.split())\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sIyKUrSvQtfu"
      },
      "outputs": [],
      "source": [
        "# Fix the import statement assuming pipeline.py and retriever.py are in the same directory\n",
        "from pipeline import DynamicRAGPipeline\n",
        "\n",
        "# Define some test queries\n",
        "test_queries = [\n",
        "    \"What are the applications of AI in healthcare?\",\n",
        "    \"Tell me about transformers in NLP.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain backpropagation.\",\n",
        "    \"What are the uses of quantum computing?\"\n",
        "]\n",
        "\n",
        "# Initialize your DA-RAG pipeline\n",
        "pipeline = DynamicRAGPipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_VpRRSeJPVPw"
      },
      "outputs": [],
      "source": [
        "# Fix the import statement assuming pipeline.py and retriever.py are in the same directory\n",
        "from pipeline import DynamicRAGPipeline\n",
        "\n",
        "# Define some test queries\n",
        "test_queries = [\n",
        "    \"What are the applications of AI in healthcare?\",\n",
        "    \"Tell me about transformers in NLP.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain backpropagation.\",\n",
        "    \"What are the uses of quantum computing?\"\n",
        "]\n",
        "\n",
        "# Initialize your DA-RAG pipeline\n",
        "pipeline = DynamicRAGPipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "e7kskjYwPQV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a78e71d-c1fc-49bc-cd42-54b075963827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "CcMjqKRGPxAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c156d3aa-0dc3-468e-8138-95b25a53d4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.11/dist-packages (6.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.32.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu sentence-transformers transformers wikipedia flask flask-cors torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "4pFrrUKURQ-4"
      },
      "outputs": [],
      "source": [
        "# Fix the import statement assuming pipeline.py and retriever.py are in the same directory\n",
        "from pipeline import DynamicRAGPipeline\n",
        "\n",
        "# Define some test queries\n",
        "test_queries = [\n",
        "    \"What are the applications of AI in healthcare?\",\n",
        "    \"Tell me about transformers in NLP.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain backpropagation.\",\n",
        "    \"What are the uses of quantum computing?\"\n",
        "]\n",
        "\n",
        "# Initialize your DA-RAG pipeline\n",
        "pipeline = DynamicRAGPipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "71cffnOrRtks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2daa9f75-d4ac-43c5-c2a8-3b9afd3cf48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Query: What are the applications of AI in healthcare?\n",
            "\n",
            "🔍 Query: Tell me about transformers in NLP.\n",
            "\n",
            "🔍 Query: What is machine learning?\n",
            "\n",
            "🔍 Query: Explain backpropagation.\n",
            "\n",
            "🔍 Query: What are the uses of quantum computing?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n🔍 Query: {query}\")\n",
        "\n",
        "    # ---- DA-RAG ----\n",
        "    da_result = pipeline.process_query(query)\n",
        "    da_response = da_result.get(\"response\", \"N/A\")\n",
        "\n",
        "    # ---- Baseline ----\n",
        "    # Fetch documents manually and pass them directly to the same BART generator\n",
        "    try:\n",
        "        docs = pipeline.retriever.fetch_wikipedia_data(query)\n",
        "        baseline_context = \"\\n\".join([doc['summary'] for doc in docs]) if docs else \"No docs found.\"\n",
        "        baseline_response = pipeline._generate_response(query, baseline_context)\n",
        "    except Exception as e:\n",
        "        baseline_response = f\"Error: {str(e)}\"\n",
        "\n",
        "    # Save results\n",
        "    results.append({\n",
        "        \"Query\": query,\n",
        "        \"DA-RAG Response\": da_response,\n",
        "        \"Baseline Response\": baseline_response,\n",
        "        \"DA-RAG Length\": len(da_response.split()),\n",
        "        \"Baseline Length\": len(baseline_response.split())\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "8-Gk5nj5UPfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c1a7c5-1db1-4947-8b61-fa14e8e52ed1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'response': \"Can you clarify what exactly you're asking about in: The reason for this?\", 'clarification_needed': True, 'topics': [('The reason for this', np.float32(0.006968446)), ('}}\\\\end{cases}}} if φ {\\\\displaystyle', np.float32(0.006968446)), ('This avoids inefficiency in', np.float32(0.006968446)), ('== Loss function ==', np.float32(0.006968446)), ('== Matrix multiplication ==', np.float32(0.006968446)), ('=== Learning as an', np.float32(0.006968446)), ('The new Δ w', np.float32(0.006968446)), ('It is an efficient', np.float32(0.006968446)), ('2)} , and target', np.float32(0.006968446)), ('== Adjoint graph ==', np.float32(0.006968446)), ('} Backpropagation then consists', np.float32(0.006968446)), ('} Note that δ', np.float32(0.006968446)), ('Now if the relation', np.float32(0.006968446)), ('1 we obtain: ∂', np.float32(0.006968446)), ('The derivative of the', np.float32(0.006968446)), ('The overall network is', np.float32(0.006968446)), ('{\\\\displaystyle \\\\delta _{j}={\\\\frac {\\\\partial', np.float32(0.006968446)), ('In machine learning, backpropagation', np.float32(0.006968446)), ('It is also dependent', np.float32(0.00644349)), ('Generally, EPSPs from synaptic', np.float32(0.00644349)), ('While there is ample', np.float32(0.00644349)), ('In addition to active', np.float32(0.00644349)), ('On average, a backpropagating', np.float32(0.00644349)), ('BDNF is an essential', np.float32(0.00644349)), ('This allows simple statistical', np.float32(0.0063471524)), ('The CAA computes, in', np.float32(0.0063471524)), ('The first network is', np.float32(0.0063471524)), ('Many modern large language', np.float32(0.0063471524)), ('The CAA exists in', np.float32(0.0063471524)), ('In machine learning, a', np.float32(0.0063471524)), ('Supervised learning is also', np.float32(0.0063471524)), ('This application underscores the', np.float32(0.0063471524)), ('Convergent recursion is a', np.float32(0.0063471524)), ('==== Backpropagation ==== Backpropagation', np.float32(0.0063471524)), ('Additionally, their application in', np.float32(0.0063471524)), ('=== Hyperparameter === A', np.float32(0.0063471524)), ('=== Topological deep learning', np.float32(0.0063471524)), ('For instance, DALL-E is', np.float32(0.0063471524)), ('== Theoretical properties ==', np.float32(0.0063471524)), ('Excellent image quality is', np.float32(0.0063471524)), ('In 1997, Alexander Dewdney,', np.float32(0.0063471524)), ('This is achieved by', np.float32(0.0063471524)), ('As a trivial example,', np.float32(0.0063471524)), ('The \"signal\" is a', np.float32(0.0063471524)), ('The simplest kind of', np.float32(0.0063471524)), ('This arises in convoluted', np.float32(0.0063471524)), ('\"But what is a', np.float32(0.0063471524)), ('Ongoing research is aimed', np.float32(0.0063471524)), ('It is a system', np.float32(0.0063471524)), ('=== Backpropagation === Backpropagation', np.float32(0.0063471524)), ('It led to the', np.float32(0.0063471524)), ('Kriesel) – Illustrated, bilingual', np.float32(0.0063471524)), ('Some of the main', np.float32(0.0063471524))], 'questions': [\"Could you provide more details about what aspect of The reason for this you're interested in?\", 'What specific information about The reason for this are you looking for?', 'Are you looking for general information about The reason for this or something specific?']}\n"
          ]
        }
      ],
      "source": [
        "query = \"Explain backpropagation.\"\n",
        "response = pipeline.process_query(query)\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3DWC2z5sVOKZ"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "pipeline = DynamicRAGPipeline()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bdKSF5bAVR8m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4f447b-3e89-4fba-eae6-17d7919729e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you clarify what exactly you're asking about in: AI is also used?\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.process_query(\"What are the applications of AI in healthcare?\")\n",
        "print(result[\"response\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Mifq-TmCa8vn"
      },
      "outputs": [],
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "pipeline = DynamicRAGPipeline()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "PucfOUg6bFu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7007cf-7912-49de-c6ed-15a6e8001f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you clarify what exactly you're asking about in: AI is also used?\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.process_query(\"What are the applications of AI in healthcare?\")\n",
        "print(result[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fTKDnVVNGn83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370aae04-01b5-49aa-96de-f83b21b1ef7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you clarify what exactly you're asking about in: AI is also used?\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.process_query(\"What are the applications of AI in healthcare?\")\n",
        "print(result[\"response\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "pXqK7VAYUQrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d1263b-7122-4c07-fbf9-9c88a97aa04e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Query: What are the applications of AI in healthcare?\n",
            "🧠 Response:\n",
            " Can you clarify what exactly you're asking about in: AI is also used?\n",
            "📊 Metrics: {}\n",
            "\n",
            "🔍 Query: Tell me about transformers in NLP.\n",
            "🧠 Response:\n",
            " Can you clarify what exactly you're asking about in: === Automatic prompt generation?\n",
            "📊 Metrics: {}\n",
            "\n",
            "🔍 Query: What is machine learning?\n",
            "🧠 Response:\n",
            " Can you clarify what exactly you're asking about in: The term inductive here?\n",
            "📊 Metrics: {}\n",
            "\n",
            "🔍 Query: Explain backpropagation.\n",
            "🧠 Response:\n",
            " Can you clarify what exactly you're asking about in: The reason for this?\n",
            "📊 Metrics: {}\n",
            "\n",
            "🔍 Query: What are the uses of quantum computing?\n",
            "🧠 Response:\n",
            " Can you clarify what exactly you're asking about in: Conversely, any problem solvable?\n",
            "📊 Metrics: {}\n"
          ]
        }
      ],
      "source": [
        "test_queries = [\n",
        "    \"What are the applications of AI in healthcare?\",\n",
        "    \"Tell me about transformers in NLP.\",\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain backpropagation.\",\n",
        "    \"What are the uses of quantum computing?\"\n",
        "]\n",
        "\n",
        "for query in test_queries:\n",
        "    print(f\"\\n🔍 Query: {query}\")\n",
        "    try:\n",
        "        result = pipeline.process_query(query)\n",
        "        print(\"🧠 Response:\\n\", result.get(\"response\", \"❌ No response\"))\n",
        "        if \"sources\" in result:\n",
        "            print(\"📚 Sources:\")\n",
        "            for src in result[\"sources\"]:\n",
        "                print(f\"- {src['title']}: {src['url']}\")\n",
        "        print(\"📊 Metrics:\", result.get(\"metrics\", {}))\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error:\", str(e))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nKNgDZV_VQE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb3d68c-7b89-48fe-8265-d551550fd4d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💬 Clarification needed. Choose one:\n",
            "1. Could you provide more details about what aspect of The term inductive here you're interested in?\n",
            "2. What specific information about The term inductive here are you looking for?\n",
            "3. Are you looking for general information about The term inductive here or something specific?\n",
            "Your choice (1-3): 1\n",
            "🧠 Final Answer:\n",
            " Can you clarify what exactly you're asking about in: This allowed for developers?\n"
          ]
        }
      ],
      "source": [
        "query = \"What is machine learning?\"\n",
        "result = pipeline.process_query(query)\n",
        "\n",
        "if result.get(\"clarification_needed\"):\n",
        "    print(\"💬 Clarification needed. Choose one:\")\n",
        "    for i, q in enumerate(result[\"questions\"]):\n",
        "        print(f\"{i+1}. {q}\")\n",
        "\n",
        "    choice = int(input(\"Your choice (1-3): \")) - 1\n",
        "    clarified_query = result[\"questions\"][choice]\n",
        "    clarified_result = pipeline.process_query(clarified_query)\n",
        "    print(\"🧠 Final Answer:\\n\", clarified_result[\"response\"])\n",
        "else:\n",
        "    print(\"🧠 Response:\\n\", result[\"response\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZcA4NYpyWgG6"
      },
      "outputs": [],
      "source": [
        "result = pipeline.process_query(\"What is machine learning?\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "vkxfzZzGYT55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92e518c-886d-4038-f77e-78b1deb0b4be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you clarify what exactly you're asking about in: The term inductive here?\n"
          ]
        }
      ],
      "source": [
        "result = pipeline.process_query(\"What is machine learning?\")\n",
        "print(result[\"response\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pipeline import DynamicRAGPipeline\n",
        "pipeline = DynamicRAGPipeline()\n",
        "response = pipeline.process_query(\"What is machine learning?\")\n",
        "print(response[\"response\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F23MSf10Ysrs",
        "outputId": "56220d4f-445f-4824-b33d-3d46be4e7fbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can you clarify what exactly you're asking about in: History?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.process_query(\"Tell me about Artificial Intelligence\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnsOaImEfkc-",
        "outputId": "f0d1b492-a922-44eb-9022-fbb0d9189625"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'response': \"Can you clarify what exactly you're asking about in: Terminology?\",\n",
              " 'clarification_needed': True,\n",
              " 'topics': ['Terminology',\n",
              "  'Characteristics',\n",
              "  'Intelligence traits',\n",
              "  'Physical traits',\n",
              "  'Tests for human-level AGI',\n",
              "  'AI-complete problems',\n",
              "  'History',\n",
              "  'Classical AI',\n",
              "  'Narrow AI research',\n",
              "  'Modern artificial general intelligence research',\n",
              "  'Feasibility',\n",
              "  'Timescales',\n",
              "  'Whole brain emulation',\n",
              "  'Early estimates',\n",
              "  'Current research',\n",
              "  'Criticisms of simulation-based approaches',\n",
              "  'Philosophical perspective',\n",
              "  '\"Strong AI\" as defined in philosophy',\n",
              "  'Consciousness',\n",
              "  'Benefits',\n",
              "  'Advancements in medicine and healthcare',\n",
              "  'Advancements in science and technology',\n",
              "  'Enhancing education and productivity',\n",
              "  'Mitigating global crises',\n",
              "  'Revitalising environmental conservation and biodiversity',\n",
              "  'Enhancing space exploration and colonization',\n",
              "  'Risks',\n",
              "  'Existential risks',\n",
              "  'Risk of loss of control and human extinction',\n",
              "  'Mass unemployment',\n",
              "  'See also',\n",
              "  'Notes',\n",
              "  'References',\n",
              "  'Sources',\n",
              "  'Further reading',\n",
              "  'External links'],\n",
              " 'questions': [\"Could you provide more details about what aspect of Terminology you're interested in?\",\n",
              "  'What specific information about Terminology are you looking for?',\n",
              "  'Are you looking for general information about Terminology or something specific?']}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}